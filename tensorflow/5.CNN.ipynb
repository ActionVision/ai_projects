{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./graphs/dl_banner.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用tensorflow low level API构建卷积神经网络\n",
    "#### \\[稀牛学院 x 网易云课程\\]《深度学习工程师(实战)》课程资料 by [@寒小阳](https://blog.csdn.net/han_xiaoyang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.知识背景：卷积神经网络\n",
    "卷积神经网络是一种在计算机视觉当中广泛应用的神经网络，其特殊的网络结构，包含卷积层、池化层等，能在共享参数的同时保证对图像特征的高效抽取。经典的卷积神经网络结构如下。\n",
    "![CNN](http://personal.ie.cuhk.edu.hk/~ccloy/project_target_code/images/fig3.png)\n",
    "\n",
    "## 0.问题背景：MNIST 手写数字\n",
    "#### \\[稀牛学院 x 网易云课程\\]《深度学习工程师(实战)》课程资料 by [@寒小阳](https://blog.csdn.net/han_xiaoyang)\n",
    "\n",
    "这是一个非常经典的问题，我们的对象是手写数字图片，我们需要根据手写数字图片的输入，构建线性的分类器(softmax分类器)去区分图片是手写数字0-9中的哪一个。这个问题的数据集，每一张图片的表示是长宽为28的矩阵，我们有时候会把它展开成784维的向量。MNIST手写数据集长成下面这样。\n",
    "\n",
    "![MNIST Dataset](http://neuralnetworksanddeeplearning.com/images/mnist_100_digits.png)\n",
    "\n",
    "更多的信息可以参考: http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.引入工具库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "session = tf.Session(config=config, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.设定超参数\n",
    "#### \\[稀牛学院 x 网易云课程\\]《深度学习工程师(实战)》课程资料 by [@寒小阳](https://blog.csdn.net/han_xiaoyang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练超参数\n",
    "learning_rate = 0.001\n",
    "num_steps = 600\n",
    "batch_size = 128\n",
    "display_step = 10\n",
    "\n",
    "# 神经网络超参数\n",
    "num_input = 784 # MNIST数据输入(数据形状: 28*28)\n",
    "num_classes = 10 # MNIST总共类别(0-9总共10个手写数字)\n",
    "dropout = 0.25 # Dropout随机失活概率\n",
    "\n",
    "\n",
    "# 占位符\n",
    "X = tf.placeholder(tf.float32, [None, num_input])\n",
    "Y = tf.placeholder(tf.float32, [None, num_classes])\n",
    "keep_prob = tf.placeholder(tf.float32) # dropout (keep probability)\n",
    "\n",
    "# 变量\n",
    "weights = {\n",
    "    # 5x5 卷积核, 1 输入, 32 输出\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    # 5x5 卷积核, 32 输入, 64 输出\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    # 全连接, 7*7*64 输入, 1024 输出\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    # 1024 输入, 10 输出(总共1类)\n",
    "    'out': tf.Variable(tf.random_normal([1024, num_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.构建模型\n",
    "#### \\[稀牛学院 x 网易云课程\\]《深度学习工程师(实战)》课程资料 by [@寒小阳](https://blog.csdn.net/han_xiaoyang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义卷积层运算(卷积层+激活层)\n",
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)\n",
    "\n",
    "# 定义池化层运算\n",
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],\n",
    "                          padding='SAME')\n",
    "\n",
    "\n",
    "# 构建卷积神经网络模型\n",
    "def conv_net(x, weights, biases, dropout):\n",
    "    # 原本MNIST数据输入是784维度向量\n",
    "    # 调整成 宽*高*通道数 的标准图片输入格式\n",
    "    # 总共是4个维度[Batch Size, Height, Width, Channel]，其中第一个维度-1表示暂时不确定一个batch多少张\n",
    "    x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "\n",
    "    # 卷积层\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    # 池化层\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # 卷积层\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    # 池化层\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    # 全连接层，需要先把数据展开成一维向量，再接全连接\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    # 随机失活层\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "\n",
    "    # 最终预估结果\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.计算损失与优化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建卷积神经网络预估结果\n",
    "logits = conv_net(X, weights, biases, keep_prob)\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "# 定义损失与优化器\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "\n",
    "# 评估模型\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# 初始化变量\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.在session当中完成计算图计算(损失计算与优化、参数更新迭代)\n",
    "#### \\[稀牛学院 x 网易云课程\\]《深度学习工程师(实战)》课程资料 by [@寒小阳](https://blog.csdn.net/han_xiaoyang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1步, 一个minibatch上的损失为 50938.1016, 训练准确率为 0.094\n",
      "第10步, 一个minibatch上的损失为 28999.7930, 训练准确率为 0.148\n",
      "第20步, 一个minibatch上的损失为 12606.2256, 训练准确率为 0.484\n",
      "第30步, 一个minibatch上的损失为 8245.8047, 训练准确率为 0.547\n",
      "第40步, 一个minibatch上的损失为 6496.4678, 训练准确率为 0.625\n",
      "第50步, 一个minibatch上的损失为 3963.8340, 训练准确率为 0.758\n",
      "第60步, 一个minibatch上的损失为 2181.0652, 训练准确率为 0.781\n",
      "第70步, 一个minibatch上的损失为 1751.7107, 训练准确率为 0.852\n",
      "第80步, 一个minibatch上的损失为 3384.8621, 训练准确率为 0.836\n",
      "第90步, 一个minibatch上的损失为 1731.7202, 训练准确率为 0.844\n",
      "第100步, 一个minibatch上的损失为 2309.3552, 训练准确率为 0.836\n",
      "第110步, 一个minibatch上的损失为 1668.9805, 训练准确率为 0.828\n",
      "第120步, 一个minibatch上的损失为 2588.8555, 训练准确率为 0.805\n",
      "第130步, 一个minibatch上的损失为 1502.3131, 训练准确率为 0.883\n",
      "第140步, 一个minibatch上的损失为 887.5152, 训练准确率为 0.930\n",
      "第150步, 一个minibatch上的损失为 1604.7382, 训练准确率为 0.891\n",
      "第160步, 一个minibatch上的损失为 1585.2931, 训练准确率为 0.867\n",
      "第170步, 一个minibatch上的损失为 1846.4788, 训练准确率为 0.844\n",
      "第180步, 一个minibatch上的损失为 1174.4926, 训练准确率为 0.906\n",
      "第190步, 一个minibatch上的损失为 841.4255, 训练准确率为 0.914\n",
      "第200步, 一个minibatch上的损失为 995.9590, 训练准确率为 0.859\n",
      "第210步, 一个minibatch上的损失为 1091.7394, 训练准确率为 0.906\n",
      "第220步, 一个minibatch上的损失为 762.1581, 训练准确率为 0.898\n",
      "第230步, 一个minibatch上的损失为 1411.2314, 训练准确率为 0.891\n",
      "第240步, 一个minibatch上的损失为 637.0445, 训练准确率为 0.906\n",
      "第250步, 一个minibatch上的损失为 686.2073, 训练准确率为 0.906\n",
      "第260步, 一个minibatch上的损失为 280.1982, 训练准确率为 0.953\n",
      "第270步, 一个minibatch上的损失为 718.5744, 训练准确率为 0.883\n",
      "第280步, 一个minibatch上的损失为 1104.5054, 训练准确率为 0.914\n",
      "第290步, 一个minibatch上的损失为 716.1561, 训练准确率为 0.906\n",
      "第300步, 一个minibatch上的损失为 392.0035, 训练准确率为 0.898\n",
      "第310步, 一个minibatch上的损失为 1025.5685, 训练准确率为 0.898\n",
      "第320步, 一个minibatch上的损失为 648.2160, 训练准确率为 0.922\n",
      "第330步, 一个minibatch上的损失为 617.3871, 训练准确率为 0.883\n",
      "第340步, 一个minibatch上的损失为 821.0640, 训练准确率为 0.898\n",
      "第350步, 一个minibatch上的损失为 606.4240, 训练准确率为 0.906\n",
      "第360步, 一个minibatch上的损失为 661.9238, 训练准确率为 0.891\n",
      "第370步, 一个minibatch上的损失为 704.5568, 训练准确率为 0.898\n",
      "第380步, 一个minibatch上的损失为 551.4064, 训练准确率为 0.938\n",
      "第390步, 一个minibatch上的损失为 249.0771, 训练准确率为 0.930\n",
      "第400步, 一个minibatch上的损失为 410.6435, 训练准确率为 0.898\n",
      "第410步, 一个minibatch上的损失为 778.2257, 训练准确率为 0.914\n",
      "第420步, 一个minibatch上的损失为 655.3400, 训练准确率为 0.914\n",
      "第430步, 一个minibatch上的损失为 131.5084, 训练准确率为 0.945\n",
      "第440步, 一个minibatch上的损失为 632.6992, 训练准确率为 0.898\n",
      "第450步, 一个minibatch上的损失为 425.2294, 训练准确率为 0.938\n",
      "第460步, 一个minibatch上的损失为 458.5821, 训练准确率为 0.883\n",
      "第470步, 一个minibatch上的损失为 302.1462, 训练准确率为 0.938\n",
      "第480步, 一个minibatch上的损失为 634.3947, 训练准确率为 0.898\n",
      "第490步, 一个minibatch上的损失为 256.4986, 训练准确率为 0.938\n",
      "第500步, 一个minibatch上的损失为 533.3555, 训练准确率为 0.867\n",
      "第510步, 一个minibatch上的损失为 810.5538, 训练准确率为 0.852\n",
      "第520步, 一个minibatch上的损失为 238.2882, 训练准确率为 0.938\n",
      "第530步, 一个minibatch上的损失为 481.8077, 训练准确率为 0.914\n",
      "第540步, 一个minibatch上的损失为 489.3539, 训练准确率为 0.914\n",
      "第550步, 一个minibatch上的损失为 204.7498, 训练准确率为 0.914\n",
      "第560步, 一个minibatch上的损失为 278.6052, 训练准确率为 0.906\n",
      "第570步, 一个minibatch上的损失为 314.3397, 训练准确率为 0.930\n",
      "第580步, 一个minibatch上的损失为 252.3342, 训练准确率为 0.938\n",
      "第590步, 一个minibatch上的损失为 301.5115, 训练准确率为 0.938\n",
      "第600步, 一个minibatch上的损失为 196.2200, 训练准确率为 0.922\n",
      "完成训练！\n",
      "测试准确率为  0.92578125\n"
     ]
    }
   ],
   "source": [
    "# 在session当中开始训练\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # 初始化\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, num_steps+1):\n",
    "        batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "        # 优化\n",
    "        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y, keep_prob: dropout})\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            # 计算准确率\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\n",
    "                                                                 Y: batch_y,\n",
    "                                                                 keep_prob: 1.0})\n",
    "            print(\"第\" + str(step) + \"步, 一个minibatch上的损失为 \" + \\\n",
    "                  \"{:.4f}\".format(loss) + \", 训练准确率为 \" + \\\n",
    "                  \"{:.3f}\".format(acc))\n",
    "\n",
    "    print(\"完成训练！\")\n",
    "\n",
    "    # 计算准确率\n",
    "    print(\"测试准确率为 \", \\\n",
    "        sess.run(accuracy, feed_dict={X: mnist.test.images[:256],\n",
    "                                      Y: mnist.test.labels[:256],\n",
    "                                      keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 版权归 © 稀牛学院 所有 保留所有权利\n",
    "![](./graphs/xiniu_neteasy.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
