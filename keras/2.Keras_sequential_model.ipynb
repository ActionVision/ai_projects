{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./img/dl_banner.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras序贯模型\n",
    "#### \\[稀牛学院 x 网易云课程\\]《深度学习工程师(实战)》课程资料 by [@寒小阳](https://blog.csdn.net/han_xiaoyang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "跃跃欲试的宝宝们，你们刚才已经见到了用Keras搭建一个神经网络有多么精简。下面我们来看一类最简单，同时也是使用最多的神经网络结果，在Keras中我们使用序贯模型对它进行构建。\n",
    "\n",
    "序贯模型是多个网络层的线性堆叠，也就是“一条路走到黑”。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.序贯模型要点\n",
    "#### \\[稀牛学院 x 网易云课程\\]《深度学习工程师(实战)》课程资料 by [@寒小阳](https://blog.csdn.net/han_xiaoyang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 简单的汉堡堆叠 or 手动加菜\n",
    "可以通过向Sequential模型传递一个layer的list来构造序贯模型，或者通过.add()方法一个个的将layer加入模型中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一次性构建汉堡\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.3\n",
    "set_session(tf.Session(config=config))\n",
    "\n",
    "model = Sequential([\n",
    "Dense(32, input_dim=784),\n",
    "Activation('relu'),\n",
    "Dense(10),\n",
    "Activation('softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ”手动加菜“\n",
    "model = Sequential()\n",
    "model.add(Dense(32, input_shape=(784,)))\n",
    "model.add(Activation('relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 告诉模型数据的维度\n",
    "模型需要知道输入数据的shape，Sequential的第一层需要接受一个关于输入数据shape的参数，后面的各个层则可以自动的推导出中间数据的shape。第一层的数据维度可以这么给进去(和Tensorflow定义placeholder有点像)：\n",
    "- 传递一个input_shape的关键字参数给第一层，input_shape是一个tuple类型的数据，其中也可以填入None，如果填入None则表示此位置可能是任何正整数。数据的batch大小不应包含在其中。\n",
    "- 有些2D层，如Dense，支持通过指定其输入维度input_dim来隐含的指定输入数据shape。一些3D的时域层支持通过参数input_dim和input_length来指定输入shape。\n",
    "- 如果你需要为输入指定一个固定大小的batch_size（常用于stateful RNN网络），可以传递batch_size参数到一个层中，例如你想指定输入张量的batch大小是32，数据shape是（6，8），则你需要传递batch_size=32和input_shape=(6,8)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_shape=784))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 编译你的模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在训练模型之前，我们需要通过compile来对学习过程进行配置。compile接收三个参数：\n",
    "\n",
    "- **优化器optimizer**：该参数可指定为已预定义的优化器名，如rmsprop、adagrad，或一个Optimizer类的对象，详情见[optimizers](http://keras-cn.readthedocs.io/en/latest/other/optimizers/)\n",
    "- **损失函数loss**：该参数为模型试图最小化的目标函数，它可为预定义的损失函数名，如categorical_crossentropy、mse，也可以为一个损失函数。详情见[losses](http://keras-cn.readthedocs.io/en/latest/other/objectives/)\n",
    "- **指标列表metrics**：对分类问题，我们一般将该列表设置为metrics=['accuracy']。指标可以是一个预定义指标的名字,也可以是一个用户定制的函数.指标函数应该返回单个张量,或一个完成metric_name - > metric_value映射的字典.请参考[性能评估](http://keras-cn.readthedocs.io/en/latest/other/metrices/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 多分类问题\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 二分类问题\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 回归问题\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mse')\n",
    "\n",
    "# 自定义metrics\n",
    "import keras.backend as K\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', mean_pred])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你的数据可以一次性读进内容进行建模，那么你会用到fit函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建与编译模型\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# 查出数据\n",
    "import numpy as np\n",
    "data = np.random.random((1000, 100))\n",
    "labels = np.random.randint(2, size=(1000, 1))\n",
    "\n",
    "# 训练与数据拟合\n",
    "history = model.fit(data, labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你的数据量很大，你可能要用到fit_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_arrays_from_file(path):\n",
    "    while 1:\n",
    "        f = open(path)\n",
    "        for line in f:\n",
    "            x, y = process_line(line)\n",
    "            img = load_images(x)\n",
    "            yield (img, y)\n",
    "        f.close()\n",
    "\n",
    "model.fit_generator(generate_arrays_from_file('/my_file.txt'),\n",
    "        samples_per_epoch=10000, nb_epoch=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.一些序贯模型的例子\n",
    "#### \\[稀牛学院 x 网易云课程\\]《深度学习工程师(实战)》课程资料 by [@寒小阳](https://blog.csdn.net/han_xiaoyang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 多层感知器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "100000/100000 [==============================] - 3s 29us/step - loss: 0.6973 - acc: 0.4989\n",
      "Epoch 2/20\n",
      "100000/100000 [==============================] - 3s 25us/step - loss: 0.6935 - acc: 0.5017\n",
      "Epoch 3/20\n",
      "100000/100000 [==============================] - 3s 25us/step - loss: 0.6934 - acc: 0.5042\n",
      "Epoch 4/20\n",
      "100000/100000 [==============================] - 3s 26us/step - loss: 0.6934 - acc: 0.4997\n",
      "Epoch 5/20\n",
      "100000/100000 [==============================] - 3s 26us/step - loss: 0.6933 - acc: 0.5010\n",
      "Epoch 6/20\n",
      "100000/100000 [==============================] - 3s 26us/step - loss: 0.6933 - acc: 0.5009\n",
      "Epoch 7/20\n",
      "100000/100000 [==============================] - 3s 26us/step - loss: 0.6933 - acc: 0.4984\n",
      "Epoch 8/20\n",
      "100000/100000 [==============================] - 3s 26us/step - loss: 0.6933 - acc: 0.4989\n",
      "Epoch 9/20\n",
      "100000/100000 [==============================] - 3s 25us/step - loss: 0.6933 - acc: 0.4979\n",
      "Epoch 10/20\n",
      "100000/100000 [==============================] - 3s 26us/step - loss: 0.6933 - acc: 0.4979\n",
      "Epoch 11/20\n",
      "100000/100000 [==============================] - 3s 27us/step - loss: 0.6933 - acc: 0.5003\n",
      "Epoch 12/20\n",
      "100000/100000 [==============================] - 3s 26us/step - loss: 0.6932 - acc: 0.5021\n",
      "Epoch 13/20\n",
      "100000/100000 [==============================] - 3s 26us/step - loss: 0.6933 - acc: 0.4988\n",
      "Epoch 14/20\n",
      "100000/100000 [==============================] - 3s 26us/step - loss: 0.6933 - acc: 0.4997\n",
      "Epoch 15/20\n",
      "100000/100000 [==============================] - 3s 26us/step - loss: 0.6933 - acc: 0.4996\n",
      "Epoch 16/20\n",
      "100000/100000 [==============================] - 3s 26us/step - loss: 0.6932 - acc: 0.5008\n",
      "Epoch 17/20\n",
      "100000/100000 [==============================] - 3s 26us/step - loss: 0.6933 - acc: 0.5008\n",
      "Epoch 18/20\n",
      "100000/100000 [==============================] - 3s 26us/step - loss: 0.6932 - acc: 0.5022\n",
      "Epoch 19/20\n",
      "100000/100000 [==============================] - 3s 26us/step - loss: 0.6932 - acc: 0.5028\n",
      "Epoch 20/20\n",
      "100000/100000 [==============================] - 3s 26us/step - loss: 0.6932 - acc: 0.5021\n",
      "100/100 [==============================] - 0s 931us/step\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Generate dummy data\n",
    "import numpy as np\n",
    "\n",
    "num=2\n",
    "\n",
    "#生成1000个数据，20维度\n",
    "x_train = np.random.random((100000, 20))\n",
    "#映射成10个类别\n",
    "y_train = keras.utils.to_categorical(np.random.randint(num, size=(100000, 1)), num_classes=num)\n",
    "x_test = np.random.random((100, 20))\n",
    "y_test = keras.utils.to_categorical(np.random.randint(num, size=(100, 1)), num_classes=num)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=20))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=sgd,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=20,\n",
    "          batch_size=128)\n",
    "score = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 卷积神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 3s 27ms/step - loss: 2.3614\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2503\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2933\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2348\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.3042\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2666\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2488\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2620\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2610\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 0s 1ms/step - loss: 2.2857\n",
      "20/20 [==============================] - 0s 10ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "#100张图片100*100大小，3通道\n",
    "x_train = np.random.random((100, 100, 100, 3))\n",
    "#10个类别\n",
    "y_train = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\n",
    "x_test = np.random.random((20, 100, 100, 3))\n",
    "y_test = keras.utils.to_categorical(np.random.randint(10, size=(20, 1)), num_classes=10)\n",
    "\n",
    "model = Sequential()\n",
    "# input: 100x100 images with 3 channels -> (100, 100, 3) tensors.\n",
    "# this applies 32 convolution filters of size 3x3 each.\n",
    "#卷积层\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(100, 100, 3)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "#拉平\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#分类问题，categorical_crossentropy\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd)\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=32, epochs=10)\n",
    "score = model.evaluate(x_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 循环神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'max_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-f1525d2d3db2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'max_features' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, output_dim=256))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=16, epochs=10)\n",
    "score = model.evaluate(x_test, y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference：https://keras-cn.readthedocs.io/en/latest/\n",
    "\n",
    "### 版权归 © 稀牛学院 所有 保留所有权利\n",
    "![](./img/xiniu_neteasy.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
